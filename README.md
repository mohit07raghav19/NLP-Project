# ğŸ” CVE NLP Analysis System

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

**Automated extraction and analysis of Common Vulnerabilities and Exposures (CVE) data using Natural Language Processing**

A comprehensive NLP project that collects, processes, and analyzes CVE data from the National Vulnerability Database (NVD), extracting structured information and providing actionable insights through advanced natural language processing techniques.

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Web Dashboard](#-web-dashboard)
- [Examples](#-examples)
- [Contributing](#-contributing)
- [License](#-license)

---

## âœ¨ Features

### ğŸ¯ Core Capabilities

- **Automated Data Collection**: Fetch CVE data from NVD API with intelligent rate limiting and caching
- **Advanced NLP Processing**:
  - Named Entity Recognition (NER) using spaCy
  - Transformer-based extraction using BERT
  - Rule-based pattern matching for CVE-specific entities
- **Multi-Model Approach**: Combines statistical and neural NLP techniques
- **Structured Information Extraction**:
  - CVE IDs and references
  - Severity scores (CVSS)
  - Affected products and vendors
  - CWE classifications
  - Temporal metadata
- **Comprehensive Analysis**:
  - Temporal trend analysis
  - Severity distribution
  - Vendor vulnerability patterns
  - Topic modeling
  - Predictive insights

### ğŸ› ï¸ Technical Features

- **Database Storage**: SQLite (with PostgreSQL support)
- **RESTful API**: FastAPI-based endpoints for data access
- **Web Dashboard**: Interactive UI for browsing and visualization
- **Google Colab Support**: Run entire pipeline in cloud environment
- **Caching & Rate Limiting**: Efficient API usage
- **Modular Architecture**: Easy to extend and customize

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CVE NLP SYSTEM                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Data Sources â”‚â”€â”€â”€â”€â”€>â”‚ Collection   â”‚â”€â”€â”€â”€â”€>â”‚  Cache   â”‚ â”‚
â”‚  â”‚  - NVD API   â”‚      â”‚   Module     â”‚      â”‚          â”‚ â”‚
â”‚  â”‚  - Scraping  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                           â”‚
â”‚                                 â–¼                           â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                      â”‚  Preprocessing   â”‚                   â”‚
â”‚                      â”‚  - Clean text    â”‚                   â”‚
â”‚                      â”‚  - Tokenize      â”‚                   â”‚
â”‚                      â”‚  - Normalize     â”‚                   â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                 â”‚                           â”‚
â”‚                                 â–¼                           â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                      â”‚  NLP Pipeline    â”‚                   â”‚
â”‚                      â”‚  - spaCy NER     â”‚                   â”‚
â”‚                      â”‚  - Transformers  â”‚                   â”‚
â”‚                      â”‚  - Rule Engine   â”‚                   â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                 â”‚                           â”‚
â”‚                                 â–¼                           â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                      â”‚  Database        â”‚                   â”‚
â”‚                      â”‚  - SQLite/       â”‚                   â”‚
â”‚                      â”‚    PostgreSQL    â”‚                   â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                 â”‚                           â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                    â–¼                         â–¼             â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚          â”‚  FastAPI     â”‚          â”‚  Analysis    â”‚       â”‚
â”‚          â”‚  REST API    â”‚          â”‚  Engine      â”‚       â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                    â”‚                         â”‚             â”‚
â”‚                    â–¼                         â–¼             â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚          â”‚  Web UI      â”‚          â”‚ Insights &   â”‚       â”‚
â”‚          â”‚  Dashboard   â”‚          â”‚ Visualize    â”‚       â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
CVE-NLP-Project/
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ task.md                     # Project requirements
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment template
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”‚
â”œâ”€â”€ config/                    # Configuration files
â”‚   â””â”€â”€ config.yaml           # Main configuration
â”‚
â”œâ”€â”€ data/                      # Data directory
â”‚   â”œâ”€â”€ raw/                  # Raw CVE data from API
â”‚   â”œâ”€â”€ processed/            # Cleaned and processed data
â”‚   â””â”€â”€ cache/               # API response cache
â”‚
â”œâ”€â”€ src/                       # Source code modules
â”‚   â”œâ”€â”€ data_collection/      # Data fetching and scraping
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ nvd_client.py    # NVD API client
â”‚   â”‚   â””â”€â”€ scraper.py       # Web scraping utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/        # Text preprocessing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cleaner.py       # Text cleaning
â”‚   â”‚   â””â”€â”€ tokenizer.py     # Tokenization
â”‚   â”‚
â”‚   â”œâ”€â”€ nlp/                  # NLP processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ner_extractor.py # Named Entity Recognition
â”‚   â”‚   â”œâ”€â”€ transformer.py   # BERT-based extraction
â”‚   â”‚   â””â”€â”€ rules.py         # Rule-based patterns
â”‚   â”‚
â”‚   â”œâ”€â”€ database/             # Database operations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py        # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schema.py        # Database schema
â”‚   â”‚   â””â”€â”€ crud.py          # CRUD operations
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/             # Analytics and visualization
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trends.py        # Temporal analysis
â”‚   â”‚   â”œâ”€â”€ statistics.py    # Statistical metrics
â”‚   â”‚   â””â”€â”€ visualize.py     # Plotting functions
â”‚   â”‚
â”‚   â””â”€â”€ utils/                # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py        # Config loader
â”‚       â””â”€â”€ logger.py        # Logging setup
â”‚
â”œâ”€â”€ api/                       # FastAPI backend
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # API entry point
â”‚   â”œâ”€â”€ routes.py            # API endpoints
â”‚   â””â”€â”€ schemas.py           # Pydantic models
â”‚
â”œâ”€â”€ ui/                        # Web interface
â”‚   â”œâ”€â”€ static/              # CSS, JS, images
â”‚   â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â””â”€â”€ img/
â”‚   â””â”€â”€ templates/           # HTML templates
â”‚       â””â”€â”€ index.html
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â”‚   â”œâ”€â”€ CVE_NLP_Pipeline.ipynb        # Main notebook
â”‚   â”œâ”€â”€ 01_Data_Collection.ipynb     # Data fetching
â”‚   â”œâ”€â”€ 02_NLP_Extraction.ipynb      # NER and extraction
â”‚   â””â”€â”€ 03_Analysis.ipynb            # Analytics
â”‚
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ setup.sh             # Project setup
â”‚   â”œâ”€â”€ download_models.py   # Download NLP models
â”‚   â””â”€â”€ run_pipeline.py      # Execute full pipeline
â”‚
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”œâ”€â”€ test_collection.py
â”‚   â”œâ”€â”€ test_nlp.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ models/                    # Saved ML models
â”‚   â””â”€â”€ .gitkeep
â”‚
â””â”€â”€ docs/                      # Documentation
    â”œâ”€â”€ setup_guide.md
    â”œâ”€â”€ api_reference.md
    â””â”€â”€ resources.md
```

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Git
- (Optional) CUDA for GPU acceleration

### Step 1: Clone Repository

```bash
git clone https://github.com/mohit07raghav19/NLP-Project.git
cd NLP-Project
```

### Step 2: Create Virtual Environment

```bash
# Create virtual environment
python -m venv venv

# Activate (macOS/Linux)
source venv/bin/activate

# Activate (Windows)
venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### Step 4: Download NLP Models

```bash
# Download spaCy model
python -m spacy download en_core_web_sm

# For better accuracy (optional, ~800MB)
python -m spacy download en_core_web_lg
```

### Step 5: Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your NVD API key (optional but recommended)
# Get free key at: https://nvd.nist.gov/developers/request-an-api-key
```

### Step 6: Initialize Database

```bash
python scripts/setup_database.py
```

---

## âš¡ Quick Start

### Option 1: Run in Google Colab (Recommended for beginners)

1. Open `notebooks/CVE_NLP_Pipeline.ipynb` in Google Colab
2. Run all cells sequentially
3. No local installation needed!

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mohit07raghav19/NLP-Project/blob/main/notebooks/CVE_NLP_Pipeline.ipynb)

### Option 2: Run Locally

```bash
# 1. Collect CVE data
python scripts/run_pipeline.py --step collection --limit 1000

# 2. Process with NLP
python scripts/run_pipeline.py --step nlp

# 3. Generate analysis
python scripts/run_pipeline.py --step analysis

# Or run complete pipeline
python scripts/run_pipeline.py --all
```

### Option 3: Use Jupyter Notebook

```bash
jupyter notebook notebooks/CVE_NLP_Pipeline.ipynb
```

### Option 4: Start Web Interface

```bash
# Start API server
uvicorn api.main:app --reload

# Open browser at http://localhost:8000
# API docs at http://localhost:8000/docs
```

---

## ğŸ“– Usage

### Data Collection

```python
from src.data_collection.nvd_client import NVDClient

# Initialize client
client = NVDClient(api_key="your_key_here")  # or None for no key

# Fetch recent CVEs
cves = client.fetch_cves(
    start_date="2024-01-01",
    end_date="2024-12-31",
    results_per_page=2000
)

# Save to file
client.save_to_json(cves, "data/raw/cves_2024.json")
```

### NLP Processing

```python
from src.nlp.ner_extractor import NERExtractor
from src.nlp.transformer import TransformerExtractor

# Initialize extractors
ner = NERExtractor(model="en_core_web_sm")
transformer = TransformerExtractor(model="bert-base-uncased")

# Extract entities from CVE description
text = "CVE-2024-1234 affects Apache Tomcat versions 9.0.0 to 9.0.70..."

entities = ner.extract_entities(text)
# Output: {'ORG': ['Apache'], 'PRODUCT': ['Tomcat'], 'VERSION': ['9.0.0', '9.0.70']}

# Use transformer for classification
severity = transformer.classify_severity(text)
# Output: {'label': 'HIGH', 'score': 0.89}
```

### Database Operations

```python
from src.database.crud import CVEDatabase

db = CVEDatabase("sqlite:///data/cve_database.db")

# Insert CVE
db.insert_cve({
    'cve_id': 'CVE-2024-1234',
    'description': '...',
    'severity': 'HIGH',
    'published_date': '2024-01-15'
})

# Query CVEs
results = db.query_cves(
    severity='HIGH',
    start_date='2024-01-01',
    vendor='Apache'
)
```

### Analysis

```python
from src.analysis.trends import TrendAnalyzer
from src.analysis.visualize import Visualizer

analyzer = TrendAnalyzer(db)
viz = Visualizer()

# Analyze temporal trends
trends = analyzer.get_temporal_trends(period='monthly')

# Create visualizations
viz.plot_severity_distribution(trends)
viz.plot_vendor_analysis(top_n=20)
viz.plot_cve_timeline()
```

---

## ğŸŒ API Documentation

### Base URL

```
http://localhost:8000
```

### Endpoints

#### Get All CVEs

```http
GET /api/v1/cves
```

**Query Parameters:**

- `limit` (int): Number of results (default: 100)
- `offset` (int): Pagination offset (default: 0)
- `severity` (str): Filter by severity (LOW, MEDIUM, HIGH, CRITICAL)
- `start_date` (str): Filter from date (YYYY-MM-DD)
- `end_date` (str): Filter to date (YYYY-MM-DD)

**Response:**

```json
{
  "total": 1000,
  "results": [
    {
      "cve_id": "CVE-2024-1234",
      "description": "...",
      "severity": "HIGH",
      "cvss_score": 7.5,
      "published_date": "2024-01-15",
      "affected_products": ["Apache Tomcat"],
      "cwe_ids": ["CWE-79"]
    }
  ]
}
```

#### Get CVE by ID

```http
GET /api/v1/cves/{cve_id}
```

#### Get Statistics

```http
GET /api/v1/statistics
```

#### Search CVEs

```http
POST /api/v1/search
Content-Type: application/json

{
  "query": "SQL injection",
  "filters": {
    "severity": ["HIGH", "CRITICAL"],
    "vendors": ["Microsoft", "Oracle"]
  }
}
```

Full API documentation available at `/docs` (Swagger UI)

---

## ğŸ¨ Web Dashboard

Access the interactive web dashboard at `http://localhost:8000` after starting the API server.

**Features:**

- ğŸ“Š Real-time statistics and charts
- ğŸ” Advanced search and filtering
- ğŸ“ˆ Temporal trend visualization
- ğŸ¢ Vendor vulnerability analysis
- ğŸ“¥ Export data (JSON, CSV)

---

## ğŸ’¡ Examples

### Example 1: Analyze Recent Critical Vulnerabilities

```python
from src.data_collection.nvd_client import NVDClient
from src.analysis.statistics import analyze_severity

client = NVDClient()
cves = client.fetch_cves(start_date="2024-01-01", severity="CRITICAL")

stats = analyze_severity(cves)
print(f"Critical CVEs in 2024: {len(cves)}")
print(f"Average CVSS Score: {stats['avg_cvss']:.2f}")
```

### Example 2: Extract Affected Products

```python
from src.nlp.ner_extractor import NERExtractor

extractor = NERExtractor()
description = "This vulnerability affects Microsoft Windows 10 and Windows 11..."

products = extractor.extract_products(description)
print(products)  # ['Microsoft Windows 10', 'Windows 11']
```

### Example 3: Generate Trend Report

```python
from src.analysis.trends import generate_report

report = generate_report(
    start_date="2023-01-01",
    end_date="2024-12-31",
    output_format="html"
)
# Saves interactive HTML report
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- National Vulnerability Database (NVD) for CVE data
- spaCy and HuggingFace for NLP tools
- FastAPI for the excellent web framework
- The open-source community

---

## ğŸ“ Contact

**Mohit Raghav**

- GitHub: [@mohit07raghav19](https://github.com/mohit07raghav19)
- Project Link: [https://github.com/mohit07raghav19/NLP-Project](https://github.com/mohit07raghav19/NLP-Project)

---

## ğŸ”— Additional Resources

- [Setup Guide](docs/setup_guide.md)
- [API Reference](docs/api_reference.md)
- [Resources & Links](docs/resources.md)
- [Changelog](CHANGELOG.md)

---

**â­ If you find this project useful, please consider giving it a star!**
